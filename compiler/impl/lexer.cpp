/**
 * @file lexer.cpp
 * @brief High-performance lexer implementation for the Yu programming language.
 *  This file is part of the Yu programming language and is licensed under MIT License;
 *  See LICENSE.txt for details
 * @note This comment block is used for Doxygen documentation, generated by AI and reviewed by maintainers.
 *
 */

#include "../lexer.h"
#include <array>
#include <cstdint>

namespace yu::compiler
{
    /**
     * @brief Char type lookup using branchless multiplication for maximum throughput
     * Each char maps to a type: whitespace(1), comment(/=2), etc.
     *
     * @note Using multiplication instead of branches improves pipelining
     * This reduces branch misprediction penalties, especially for high-entropy input.
    */
    static const std::array<uint8_t, 256> char_type = []
    {
        std::array<uint8_t, 256> types {};
        for (auto i = 0; i < 256; ++i)
        {
            types[i] = (i == ' ' || i == '\t' || i == '\n' || i == '\r') * 1 +
                       (i == '/') * 2 +
                       (i == '*') * 3 +
                       (std::isalpha(i) || i == '_' || i == '@') * 4 +
                       std::isdigit(i) * 5 +
                       (i == '"') * 6;
        }
        return types;
    }();

    /**
     * @brief Single character tokens for fast lookup
    */
    static const std::array<lang::token_i, 256> single_char_tokens = []
    {
        alignas(CACHE_LINE_SIZE) std::array<lang::token_i, 256> tokens {};
        std::fill(tokens.begin(), tokens.end(), lang::token_i::UNKNOWN);

        tokens['+'] = lang::token_i::PLUS;
        tokens['-'] = lang::token_i::MINUS;
        tokens['*'] = lang::token_i::STAR;
        tokens['/'] = lang::token_i::SLASH;
        tokens['%'] = lang::token_i::PERCENT;
        tokens['='] = lang::token_i::EQUAL;
        tokens['!'] = lang::token_i::BANG;
        tokens['<'] = lang::token_i::LESS;
        tokens['>'] = lang::token_i::GREATER;
        tokens['&'] = lang::token_i::AND;
        tokens['|'] = lang::token_i::OR;
        tokens['^'] = lang::token_i::XOR;
        tokens['~'] = lang::token_i::TILDE;
        tokens['.'] = lang::token_i::DOT;
        tokens['('] = lang::token_i::LEFT_PAREN;
        tokens[')'] = lang::token_i::RIGHT_PAREN;
        tokens['{'] = lang::token_i::LEFT_BRACE;
        tokens['}'] = lang::token_i::RIGHT_BRACE;
        tokens['['] = lang::token_i::LEFT_BRACKET;
        tokens[']'] = lang::token_i::RIGHT_BRACKET;
        tokens[','] = lang::token_i::COMMA;
        tokens[':'] = lang::token_i::COLON;
        tokens[';'] = lang::token_i::SEMICOLON;
        tokens['?'] = lang::token_i::QUESTION;

        return tokens;
    }();

    /**
     *  @brief Mapping of token text to token type
    */
    static constexpr std::array<lang::token_i, 7> type_to_token = {
        lang::token_i::UNKNOWN,     // 0
        lang::token_i::UNKNOWN,     // type 1 (whitespace)
        lang::token_i::UNKNOWN,     // type 2 (comment start)
        lang::token_i::UNKNOWN,     // type 3 (comment end)
        lang::token_i::IDENTIFIER,  // type 4
        lang::token_i::NUM_LITERAL, // type 5
        lang::token_i::STR_LITERAL  // type 6
    };

    /**
     * @brief Mapping of hex numbers to their decimal values
    */
    static constexpr std::array<uint8_t, 256> hex_lookup = []
    {
        std::array<uint8_t, 256> table {};
        for (int i = '0'; i <= '9'; ++i)
            table[i] = 1;
        for (int i = 'a'; i <= 'f'; ++i)
            table[i] = 1;
        for (int i = 'A'; i <= 'F'; ++i)
            table[i] = 1;
        return table;
    }();

    /**
     * @brief Mapping of binary numbers to their decimal values
    */
    static constexpr std::array<uint8_t, 256> bin_lookup = []
    {
        std::array<uint8_t, 256> table {};
        table['0'] = table['1'] = 1;
        return table;
    }();

    /**
     * @brief Mapping of valid escape sequences
    */
    static constexpr std::array<uint8_t, 256> valid_escapes = []
    {
        std::array<uint8_t, 256> table {};
        table['n'] = table['t'] = table['r'] = table['\\'] =
                                               table['"'] = table['0'] = table['x'] = 1;
        return table;
    }();

    /**
     * @brief Helper function to create a flag based on a condition
     * @param condition boolean The condition to check
     * @param flag lang::token_flags The flag to set
    */
    ALWAYS_INLINE constexpr uint8_t make_flag(const bool condition, lang::token_flags flag)
    {
        return condition ? static_cast<uint8_t>(flag) : 0;
    }

    /**
     * @brief Prefetching strategy for optimal cache utilization
     * L1: Next immediate chunk (64 bytes)
     * L2: Near-future chunk (256 bytes)
     * L3: Far-future chunk (512 bytes)
     * This pattern matches typical token parsing flow where we need
     * to look ahead for multi-character tokens and comments
    */
    ALWAYS_INLINE void Lexer::prefetch_next() const
    {
        PREFETCH_L1(src + current_pos + CACHE_LINE_SIZE);
        PREFETCH_L2(src + current_pos + CACHE_LINE_SIZE * 4);
        PREFETCH_L3(src + current_pos + CACHE_LINE_SIZE * 8);
    }

    /**
     * @brief Creates a lexer object.
     * @param src The source code to tokenize.
     * @return Lexer The lexer object.
     * @throws std::runtime_error if the source file is too large (>4GiB).
    */
    Lexer create_lexer(const std::string_view src)
    {
        Lexer lexer;
        lexer.src = src.data();
        lexer.src_length = static_cast<uint32_t>(src.length());
        lexer.current_pos = 0;
        lexer.tokens.reserve(src.length() / 4);
        lexer.line_starts.reserve(src.length() / 40);
        lexer.line_starts.emplace_back(0);
        return lexer;
    }

    /**
     * @brief Skips whitespace and comments
     * @param lexer The lexer object.
     * @param src The source code.
     * @param current_pos The current position in the source code.
     * @param src_length The length of the source code.
     *
     * @note This function is inlined for maximum performance
     * This loop processes whitespace and comments:
     * - Single-line comments ('//') skip to the next newline.
     * - Multi-line comments
     * - Whitespace advances the cursor, but non-whitespace exits the loop.
    */
    ALWAYS_INLINE HOT_FUNCTION
    void skip_whitespace_comment(Lexer &lexer, const char *src,
                                 uint32_t &current_pos, const uint32_t src_length)
    {
        // Fast path for skipping whitespace and comments
        while (current_pos + 8 <= src_length)
        {
            const uint64_t chunk = *reinterpret_cast<const uint64_t *>(src + current_pos);
            const uint64_t whitespace = chunk ^ 0x2020202020202020ULL; // spaces bit
            const uint64_t slashes = chunk ^ 0x2F2F2F2F2F2F2F2FULL;    // forward slashes
            if (!whitespace)
            {
                current_pos += 8;
                continue;
            }

            if (slashes == 0)
                break;

            current_pos += __builtin_ctzll(whitespace) / 8;
            break;
        }

        while (current_pos < src_length)
        {
            const char current_char = src[current_pos];
            const uint8_t type = char_type[static_cast<uint8_t>(current_char)];
            const uint32_t is_newline = current_char == '\n';
            lexer.line_starts.emplace_back(current_pos + 1 * is_newline);
            const bool has_next = current_pos + 1 < src_length;
            const char next_char = has_next ? src[current_pos + 1] : '\0';

            const uint32_t is_slash = type == 2;
            const uint32_t is_single_comment = is_slash & (next_char == '/');
            const uint32_t is_multi_comment = is_slash & (next_char == '*');

            current_pos += 2 * is_single_comment;
            while (is_single_comment && current_pos < src_length && src[current_pos] != '\n')
                ++current_pos;

            current_pos += 2 * is_multi_comment;
            uint32_t in_comment = is_multi_comment;
            while (in_comment && current_pos + 1 < src_length)
            {
                const uint32_t end_of_comment = src[current_pos] == '*' & src[current_pos + 1] == '/';
                lexer.line_starts.emplace_back(current_pos + 1 * (src[current_pos] == '\n'));

                current_pos += 1 + end_of_comment;
                in_comment &= !end_of_comment;
            }

            const uint32_t should_continue = type == 1;
            current_pos += should_continue;

            if (!(should_continue | is_single_comment | is_multi_comment))
                return;
        }
    }

    /**
     * @brief Returns the next token.
     * @param lexer The lexer object.
     * @return token_t The next token.
    */
    ALWAYS_INLINE HOT_FUNCTION lang::token_t next_token(Lexer &lexer)
    {
        skip_whitespace_comment(lexer, lexer.src, lexer.current_pos, lexer.src_length);

        if (UNLIKELY(lexer.current_pos >= lexer.src_length))
            return { lexer.current_pos, 0, lang::token_i::END_OF_FILE, 0 };

        switch (const char c = lexer.src[lexer.current_pos]; char_type[static_cast<uint8_t>(c)])
        {
            case 4:
                return lex_identifier(lexer);
            case 5:
                return lex_number(lexer);
            case 6:
                return lex_string(lexer);
            default:
                return { lexer.current_pos, 1, single_char_tokens[static_cast<uint8_t>(c)], 0 };
        }
    }

    /**
     * @brief Parses numeric literals including:
     * - Binary ('0b...'), Hexadecimal ('0x...'), Decimal, and Floating-point.
     * - Validates characters using `hex_lookup` and `bin_lookup` tables.
     * - Tracks the presence of a decimal point for floating-point literals.
     *
     * The flags set during parsing are used to determine the token's type.
     */
    ALWAYS_INLINE HOT_FUNCTION lang::token_t lex_number(const Lexer &lexer)
    {
        const char *start = lexer.src + lexer.current_pos;
        const char *current = start;
        const char *end = lexer.src + lexer.src_length;
        uint8_t flags = 0;

        // Fast path for skipping numbers
        if (LIKELY(*current >= '0' && *current <= '9'))
        {
            while (current + 8 <= end)
            {
                const uint64_t chunk = *reinterpret_cast<const uint64_t *>(current);
                const uint64_t digit_test = chunk - 0x3030303030303030ULL;
                const uint64_t digit_test2 = chunk + 0x4646464646464646ULL;
                current += 8 * !((digit_test | digit_test2) & 0x8080808080808080ULL);
                if ((digit_test | digit_test2) & 0x8080808080808080ULL)
                    break;
            }
        }

        const uint32_t has_next = current + 1 < end;
        const char next = current[has_next];
        const uint32_t is_zero = *current == '0';
        const uint32_t is_x = (next | 32) == 'x'; // Makes both 'x' and 'X' == 'x'
        const uint32_t is_b = (next | 32) == 'b'; // Makes both 'b' and 'B' == 'b'
        const uint32_t is_hex = is_zero & is_x;
        const uint32_t is_bin = is_zero & is_b;

        current += 2 * (is_hex | is_bin);

        uint32_t has_decimal = 0;
        while (current < end)
        {
            const char c = *current;
            const uint32_t is_digit = (c >= '0' && c <= '9');
            const uint32_t is_dot = c == '.';
            const uint32_t is_valid_hex = hex_lookup[static_cast<uint8_t>(c)];
            const uint32_t is_valid_bin = bin_lookup[static_cast<uint8_t>(c)];
            const uint32_t is_valid = (is_hex & is_valid_hex) |
                                      (is_bin & is_valid_bin) |
                                      ((!is_hex & !is_bin) & (is_digit | is_dot));

            if (!is_valid)
                break;

            has_decimal += is_dot;
            flags |= (has_decimal > 1) * static_cast<uint8_t>(lang::token_flags::MULTIPLE_DECIMAL_POINTS);

            ++current;
        }

        const uint32_t at_exp = current < end;
        const uint32_t is_exp = at_exp & ((*current | 32) == 'e');
        current += is_exp;

        const uint32_t has_sign = (current < end) & ((*current == '+') | (*current == '-'));
        current += is_exp * has_sign;

        const uint32_t exp_valid = (current < end) & ((*current >= '0') & (*current <= '9'));
        flags |= (is_exp & !exp_valid) * static_cast<uint8_t>(lang::token_flags::INVALID_EXPONENT);

        const uint32_t should_continue = is_exp & exp_valid;
        while (should_continue & (current < end) & ((*current >= '0') & (*current <= '9')))
            ++current;

        return {
            lexer.current_pos,
            static_cast<uint16_t>(current - start),
            lang::token_i::NUM_LITERAL,
            flags
        };
    }

    /**
     * @brief Checks if the token is a string literal. Allows for escape sequences.
     * @param lexer The lexer object.
     * @return token_t The token type.
    */
    ALWAYS_INLINE HOT_FUNCTION lang::token_t lex_string(const Lexer &lexer)
    {
        const char *start = lexer.src + lexer.current_pos;
        const char *current = start + 1;
        const char *end = lexer.src + lexer.src_length;
        uint8_t flags = 0;

        while (current < end)
        {
            const char c = *current;
            const uint32_t is_escape = c == '\\';
            const uint32_t has_next = current + 1 < end;
            const char next = current[has_next];

            const uint32_t is_quote = c == '"';
            const uint32_t is_valid_escape = valid_escapes[static_cast<uint8_t>(next)];
            const uint32_t escape_advance = is_escape * (1 + (next == 'x') * 2);

            flags |= make_flag(is_escape & !is_valid_escape,
                               lang::token_flags::INVALID_ESCAPE_SEQUENCE);

            current += 1 + escape_advance;
            if (is_quote | (is_escape & !is_valid_escape))
                break;
        }

        flags |= make_flag(current >= end || *(current - 1) != '"',
                           lang::token_flags::UNTERMINATED_STRING);
        return {
            lexer.current_pos,
            static_cast<uint16_t>(current - start),
            lang::token_i::STR_LITERAL,
            flags
        };
    }

    /**
     * @brief Checks if the token is a keyword or an identifier or a type.
     * @param lexer The lexer object.
     * @return token_t The token type.
    */
    ALWAYS_INLINE HOT_FUNCTION lang::token_t lex_identifier(const Lexer &lexer)
    {
        const char *start = lexer.src + lexer.current_pos;
        const char *current = start;
        uint8_t flags = 0;

        const uint32_t is_valid_start = (*current == '_' || *current == '@' ||
                                         std::isalpha(*current));
        flags |= make_flag(!is_valid_start, lang::token_flags::INVALID_IDENTIFIER_START);

        current += (*current == '@');

        while (current < lexer.src + lexer.src_length)
        {
            const char c = *current;
            const uint32_t is_alnum = std::isalnum(c);
            const uint32_t is_underscore = c == '_';
            const uint32_t is_space = std::isspace(c);
            const uint32_t is_punct = std::ispunct(c);

            const uint32_t is_valid = is_alnum | is_underscore;
            const uint32_t is_terminator = (!is_valid) & (is_space | is_punct);

            flags |= (!is_valid & !is_terminator) *
                    static_cast<uint8_t>(lang::token_flags::INVALID_IDENTIFIER_CHAR);

            current += is_valid;
            if (!is_valid)
                break;
        }

        const uint16_t length = current - start;
        const std::string_view text(start, length);

        for (const auto &[token_text, token_type]: lang::token_map)
        {
            if (token_text.length() == length &&
                memcmp(token_text.data(), text.data(), length) == 0)
            {
                return { lexer.current_pos, length, token_type, flags };
            }
        }

        return { lexer.current_pos, length, lang::token_i::IDENTIFIER, flags };
    }

    /**
     * @brief Tokenizes the source code and returns the token type.
     * @param lexer The lexer object.
     * @return token_i The token type.
    */
    lang::TokenList *tokenize(Lexer &lexer)
    {
        uint32_t state = 1;
        while (state)
        {
            lang::token_t token = next_token(lexer);
            lexer.tokens.push_back(token);

            state = token.type != lang::token_i::END_OF_FILE;
            lexer.current_pos += token.length * state;
            lexer.prefetch_next();
        }

        return &lexer.tokens;
    }

    /**
     * @brief Get the line and column for a given token.
     * @param lexer The lexer object.
     * @param token The token.
     * @return std::pair<uint32_t, uint32_t> The line and column.
    */
    HOT_FUNCTION std::pair<uint32_t, uint32_t> get_line_col(const Lexer &lexer, const lang::token_t &token)
    {
        const auto it = std::upper_bound(lexer.line_starts.begin(), lexer.line_starts.end(), token.start);
        return { std::distance(lexer.line_starts.begin(), it), token.start - *(it - 1) + 1 };
    }

    /**
     * @brief Checks if the token is a keyword or an identifier or a type.
     * @param c The character to check.
     * @return token_i The token type.
    */
    HOT_FUNCTION lang::token_i get_token_type(const char c)
    {
        const uint8_t char_class = char_type[static_cast<uint8_t>(c)];
        const lang::token_i single_token = single_char_tokens[static_cast<uint8_t>(c)];
        const lang::token_i type_token = type_to_token[char_class];

        return (single_token != lang::token_i::UNKNOWN) ? single_token : type_token;
    }

    /**
     * @brief Get the string value of a token.
     * @param lexer The lexer object.
     * @param token The token.
     * @overload pos The position of the token in the token list.
     * @return std::string_view The string value of the token.
    */
    std::string_view get_token_value(const Lexer &lexer, const lang::token_t &token)
    {
        return { lexer.src + token.start, token.length };
    }

    std::string_view get_token_value(const char *src, const lang::TokenList &tokens, size_t pos)
    {
        return {
            src + tokens.starts[static_cast<std::vector<unsigned>::size_type>(pos)],
            tokens.lengths[static_cast<std::vector<unsigned>::size_type>(pos)]
        };
    }
}
